{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "<i>This code was authored by the 8.S50x Course Team, Copyright 2021 MIT All Rights Reserved.</i>\n",
    "<hr style=\"height: 1px;\">\n",
    "<br>\n",
    "\n",
    "# RECITATION 13: Metropolis–Hastings algorithm for MCMC\n",
    "\n",
    "<br>\n",
    "<!--end-block--> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 13.0 Overview of Learning Objectives\n",
    "\n",
    "\n",
    "In this recitation, we will explore the following concepts:\n",
    "\n",
    "- What is a Markov Process?\n",
    "- How do you implement Metropolis-Hastings?\n",
    "- What are some pros and cons of MCMC/Metropolis-Hastings?\n",
    "- How can you use MCMC for parameter estimation?\n",
    "\n",
    "This recitation will walk you through the implementation of the Metropolis-Hastings algorithm,\n",
    "which should make the last part of Project 3 less \"black-boxy\".\n",
    "\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 13.1 MCMC\n",
    "\n",
    "A <a href=\"https://en.wikipedia.org/wiki/Markov_chain\">markov process</a> is a probabilistic process or sequence of events $\\{X_i\\}$ with the memory-less property i.e. the probability of each event depends only on the state attained in the previous event or\n",
    "$$\n",
    "P(X_t | X_{t-1}, \\cdots, X_{0}) = P(X_t | X_{t-1})\n",
    "$$\n",
    "\n",
    "\n",
    "<a href=\"https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo\">Markov Chain Monte Carlo</a>\n",
    "(MCMC) is a method for sampling arbitrary probability distributions. MCMCs rely on the fact that a markov process has a unique equilibrium distribution which can be constructed such that it is identical to the target distribution. \n",
    "\n",
    "> Note: Let $\\pi$ be the equilibrium distribution of a Markov chain, if $X_t \\sim \\pi$ then $X_{t+1} \\sim \\pi$. \n",
    "\n",
    "The process converges to the equilibrium distribution after a number of steps. Thus, the more steps are taken in the process, the more closely the distribution of the sample matches the actual desired distribution. Various algorithms exist for constructing these chains, including the Metropolis–Hastings algorithm which we will discuss next.\n",
    "\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 13.2 Metropolis-Hastings\n",
    "\n",
    "\n",
    "<a href=\"https://en.wikipedia.org/wiki/Metropolis–Hastings_algorithm\">Metropolis-Hastings</a>\n",
    "is a particular MCMC sampling algorithm. The goal is to generate samples from some target distribution $P(x)$ (for our purposes this will be the posterior $p(x | D)$) where $x$ is a vector of the parameters we would like to estimate and $D$ is the observed dataset.\n",
    "It relies on a proposal density or jumping distribution, $g(y|x)$ used to jump from one proposed sample ($x$) to the next ($y$) with some probability. The equilibrium distribution of the Markov Chain generated is exactly the desired distribution $P(x)$. The proof for this can be found in any standard text and will not be covered here.\n",
    "\n",
    "The algorithm itself is quite straightforward.\n",
    "\n",
    "1. Sample a proposal value $y_t$ from the jumping distribution $g(y_t|x_{t-1})$.\n",
    "\n",
    "2. Compute the acceptance probability \n",
    "    $$\n",
    "    p_t = \\rm{min}\\big[1,\\, \\frac{g(y_t|x_{t-1})}{g(x_{t-1}|y_t)} \\frac{P(y_t)}{P(x_{t-1})}\\big]\n",
    "    $$\n",
    "    if the proposal distribution is symmetric (i.e. $g(x|y) = g(y|x)$) then the probability is simply \n",
    "    $$\n",
    "    p_t = \\rm{min}\\big[1,\\, \\frac{P(y_t)}{P(x_{t-1})} \\big]\n",
    "    $$\n",
    "    As mentioned earlier, our target distribution is the posterior. So $P(x)$ is to be replaced with $\\frac{p(D|x)p(x)}{p(D)}$ where $p(x)$ is the prior and $p(D|x)$ is the likelihood.\n",
    "\n",
    "3. With probability $p_t$ accept the proposed sample:\n",
    "\n",
    "    1. Sample $u_t$ from $\\mathcal{U}(0,1)$, the uniform distribution between 0 and 1.\n",
    "\n",
    "    2. If $p_t>u_t$ accept the sample by setting $x_t = y_t$. Otherwise remain at $x_{t-1}$.\n",
    "\n",
    "Repeat until an adequate number of samples is generated.\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will generate some sample data from a normal distribution. Out of 10K data points, we will initially select 1000 to use as our observed data. Using a smaller sample will allow you to play around with the various parts of the algorithm because everything runs faster. We will make the observed dataset bigger for the final analysis. The goal, for now, is to get an intuition for MCMCs and how they can be used to do parameter estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu_true = 10\n",
    "sigma_true = 5\n",
    "data = np.random.normal(mu_true, sigma_true, 10000)\n",
    "obs = np.random.choice(data, 1000, replace=False)\n",
    "\n",
    "plt.hist(data, bins=50, label='All data', density=True, alpha=1, histtype='step')\n",
    "plt.hist(obs, bins=20, label='Observations', density=True, alpha=0.8, histtype='stepfilled')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 13.3 Exercise 1\n",
    "\n",
    "\n",
    "Now we will implement some of the moving parts of Metropolis-Hastings to sample from the posterior of the mean only. (You can do both mu and sigma later).\n",
    "\n",
    "1) First implement a likelihood function which takes in the parameter vector (this is just mu for now)\n",
    "and returns the likelihood of the observed data under those parameter values.\n",
    "\n",
    "2) Implement a proposal distribution/ transition model.\n",
    "\n",
    "3) Implement a prior for the parameters.\n",
    "\n",
    "Note: You should work in log space as much as possible for numerical stability. If you see NaNs, you are probably multiplying very small/large values.\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(D, mu, sigma):\n",
    "    \"\"\"Returns the likelihood of the data given the parameters\n",
    "\n",
    "    Args:\n",
    "        D (array[float]): Array of observed data points.\n",
    "        mu (float): Mean of the distribution.\n",
    "        sigma (float): Standard deviation of the distribution.\n",
    "\n",
    "    Returns:\n",
    "        float: likelihood of the data given the parameters.\n",
    "    \"\"\"    \n",
    "    log_likelihood = stats.norm.logpdf(D, mu, sigma).sum()\n",
    "    # Implement a likelihood function for the model used to generate the data\n",
    "    # make sure to avoid multiplying very small numbers to avoid underflow\n",
    "    return log_likelihood# return a single value for the likelihood/loglikelihood for the entire dataset: p(x|D)\n",
    "# you can also use stats.norm from scipy \n",
    "# which implements methods for all sorts of useful things like the pdf and cdf\n",
    "\n",
    "\n",
    "def transition_model(x):\n",
    "    \"\"\"Returns the next state of the Markov chain given the current state x.\n",
    "\n",
    "    Args:\n",
    "        x (float or array[float]): Current state of the Markov chain. \n",
    "\n",
    "    Returns:\n",
    "        float or array[float]: Next state of the Markov chain.\n",
    "    \"\"\"    \n",
    "    new_x = np.random.normal(x, .1)\n",
    "    # Implement a symmetric transition model\n",
    "    # Remember if the transition density is not symmetric, \n",
    "    # you will need to account for this term in the acceptance probability\n",
    "\n",
    "    # For now we will run the MCMC over the mean only and assume we know the true sigma\n",
    "    # An easy transition_model is to sample from a normal distribution around the current mean\n",
    "    return new_x\n",
    "\n",
    "def prior(x):\n",
    "    \"\"\"Returns the prior probability of the current state x. \n",
    "\n",
    "    Args:\n",
    "        x (float or array[float]): Current state of the Markov chain. \n",
    "\n",
    "    Returns:\n",
    "        float: p(x)\n",
    "    \"\"\"    \n",
    "    log_prior = stats.norm.logpdf(x, 11, 5)\n",
    "    # Implement a prior for mu you can pick a uniform prior or something else\n",
    "    return log_prior# return a single value for the prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's combine these pieces to implement the metropolis-hastings algorithm (see above for details). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(mu, sigma):\n",
    "    # A single step of the Markov chain\n",
    "    # This function should return the new value of mu and sigma\n",
    "    # and the loglikelihood of the new value\n",
    "    # You will change this later to step over sigma as well\n",
    "    return transition_model(mu), sigma, likelihood(obs, mu, sigma)\n",
    "\n",
    "def metro_hastings(mu, sigma, n_samples=1000):\n",
    "    # Implement the Metropolis-Hastings algorithm\n",
    "    samples = []\n",
    "    while i< n_samples:\n",
    "        new_mu, sigma, log_likelihood, log_prior = step(data, mu, 5)\n",
    "        log_ratio = prior(new_mu) + likelihood(data, new_mu, sigma) - (log_likelihood\n",
    "    \n",
    "    return # samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run your Metropolis-Hastings algorithm\n",
    "# to generate 1000 samples\n",
    "samples, sample_index, all_mus= metro_hastings(0, 5, n_samples=1000)\n",
    "print(\"acceptancerate:\", len(samples)/len(all_mus))\n",
    "# What is your acceptance rate?\n",
    "# What determines this value? How can you make it larger?\n",
    "# Hint: try changing your jumping distribution\n",
    "plt.scatter(sample_index, samples, alpha =.5, s=10)\n",
    "plt.show()\n",
    "\n",
    "# Make some plots to visualize your markov chain with (parameter as a function of step for example)\n",
    "# both accepted and rejected proposals\n",
    "# What happens in the early steps?\n",
    "# This is why there is a \"burn-in\" phase in MCMC methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cases we want to generate independent identically distributed samples.\n",
    "Let's check if that's what we got.\n",
    "\n",
    "The function plt.accor plots the correlation between samples at different distances $\\tau$,\n",
    " $$C(\\tau) = Corr(x_t,x_{t-\\tau})$$\n",
    " at $\\tau = 0$, $C(0)$ is always 1 since it's the correlation of a random variable with itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use plt.acorr to plot the autocorrelation of the samples you generated \n",
    "# (make sure to remove the mean first i.e. samples - np.mean(samples))\n",
    "# and compare that to a true i.i.d sample from a normal distribution (np.random.randn)\n",
    "# Do you notice a problem?\n",
    "# Try the same thing with every 10th sample for example. You should notice less autocorrelation.\n",
    "# This is why people use \"thinning\" in MCMC methods.\n",
    "# Another way to fix this is to use a proposal distribution with larger step sizes.\n",
    "\n",
    "plt.acorr(np.random.randn(1000), maxlags=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 13.3 Exercise 2\n",
    "\n",
    "\n",
    "Now we will do some parameter estimation!\n",
    "Hints:\n",
    "The mean of the sample can be a good estimator.\n",
    "A 95% credible interval (CI) is an interval which contains\n",
    "the true value of the parameter $\\theta$ with probability 0.95. \n",
    "You can find a few examples of ways to construct a CI here\n",
    "https://en.wikipedia.org/wiki/Credible_interval\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a 90% Credible Interval for the true mean using\n",
    "the samples you generated from MCMC. You can use the function np.percentile from numpy\n",
    "to compute the percentiles of the samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_327/2250754349.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# your results.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxvline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Estimated Mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mCI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m97.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'samples' is not defined"
     ]
    }
   ],
   "source": [
    "# Make a histogram of your samples (don't forget about burn-in)\n",
    "# Plot your best estimate of the true mean\n",
    "# along with the edges of your credible interval.\n",
    "# Are the results reasonable?\n",
    "# How can you have a \"better\" interval?\n",
    "# Hint: Investigate how the number of observations affects\n",
    "# your results.\n",
    "\n",
    "plt.hist(samples[100::], bins=50, density=True, alpha=.5)\n",
    "plt.axvline(mu_true, color='r', linestyle='--', label='Estimated Mean')\n",
    "CI = np.percentile(samples[100::], [2.5, 97.5])\n",
    "plt.axcline(CI[0], color='g', linestyle='--', label = '95% CI')\n",
    "plt.axcline(CI[1], color='g', linestyle='--')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: \n",
    "# Run the MCMC algorithm for both mu and sigma \n",
    "# and plot the mean and the 90% CI\n",
    "\n",
    "# How can you make the MCMC algorithm more efficient?\n",
    "# How can you make the samples independent?\n",
    "# The answer can be found here: https://arxiv.org/pdf/2101.08176.pdf\n",
    "# The key idea is that you can use \"Normalizing Flows\" to approximate\n",
    "# the target distribution which you can then correct using Metropolis-Hastings\n",
    "# to obtain an exact i.i.d sample of the target distribution. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c34b3f829f55344124a5a0f2100dda58adb8e3cad3250906cc72bb8dd00bb6e7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
